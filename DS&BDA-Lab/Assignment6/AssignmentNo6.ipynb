{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment No : 06 (Naïve Bayes classification)"
      ],
      "metadata": {
        "id": "9Hd_OG_GJXiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART I :-"
      ],
      "metadata": {
        "id": "O0LoQ4pCJmTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Creating a simple dataset\n",
        "data = {\n",
        "    'Age': [22, 25, 47, 52, 46, 56, 60, 62, 23, 24],\n",
        "    'Salary': [20000, 25000, 50000, 52000, 48000, 60000, 80000, 81000, 21000, 22000],\n",
        "    'Purchased': [0, 0, 1, 1, 1, 1, 1, 1, 0, 0]  # 1 = Purchased, 0 = Not Purchased\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df[['Age', 'Salary']]\n",
        "y = df['Purchased']\n",
        "# Split data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Initialize Gaussian Naïve Bayes model\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49p4Bsi-xlzO",
        "outputId": "2bfccf4c-b9f6-4a5a-9e03-2e98bd51b2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2]]\n",
            "Accuracy: 1.00\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART II :-"
      ],
      "metadata": {
        "id": "Zm9qPA_HJu9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "# Sample Dataset (Replace this with a real dataset)\n",
        "data = {\n",
        "    'Text': [\n",
        "        \"Win a free iPhone now!\",\n",
        "        \"Limited time offer, buy now!\",\n",
        "        \"Meeting at 10 AM, please join.\",\n",
        "        \"Get a discount on your next purchase!\",\n",
        "        \"Let's catch up over coffee.\",\n",
        "        \"Your loan is pre-approved. Click here!\"\n",
        "    ],\n",
        "    'Label': ['spam', 'spam', 'ham', 'spam', 'ham', 'spam']  # Spam or Ham (Not Spam)\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to clean text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "    words = text.split()\n",
        "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['Cleaned_Text'] = df['Text'].apply(preprocess_text)\n",
        "vectorizer = TfidfVectorizer()  # TF-IDF Vectorization\n",
        "X = vectorizer.fit_transform(df['Cleaned_Text'])\n",
        "y = df['Label'].map({'spam': 1, 'ham': 0})  # Convert labels to 1 (Spam) and 0 (Ham)\n",
        "# Split Data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "# Predict on Test Data\n",
        "y_pred = model.predict(X_test)\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Classification Report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print Results\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B085oeA3yWiW",
        "outputId": "0340359c-588f-4ab7-bb93-e00d4632f5ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[0 0]\n",
            " [2 0]]\n",
            "Accuracy: 0.00\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       2.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}